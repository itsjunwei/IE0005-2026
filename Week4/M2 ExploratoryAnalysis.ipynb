{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis in Python\n",
    "\n",
    "Dataset from Kaggle : **\"Pokemon with stats\"** by *Alberto Barradas*  \n",
    "Source: https://www.kaggle.com/abcsds/pokemon (requires login)\n",
    "\n",
    "Inspired by the wonderful EDA on Pokemon Data by [Redwan Huq](http://inmachineswetrust.com/posts/exploring-pokemon-dataset/).\n",
    "\n",
    "![Gotta Catch 'Em All!](images/PokemonIntro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Essential Libraries\n",
    "\n",
    "Let us begin by importing the essential Python Libraries.\n",
    "\n",
    "> NumPy : Library for Numeric Computations in Python  \n",
    "> Pandas : Library for Data Acquisition and Preparation  \n",
    "> Matplotlib : Low-level library for Data Visualization  \n",
    "> Seaborn : Higher-level library for Data Visualization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Don't do this unless you know what you're doing.\n",
    "I'm only including this to remove the warning statements that may overflow the notebook\n",
    "\"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Import the Dataset\n",
    "\n",
    "The dataset is in CSV format; hence we use the `read_csv` function from Pandas.  \n",
    "Immediately after importing, take a quick look at the data using the `head` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pd.read_csv() because the data is in a \"Comma Separated Values\" (csv) file\n",
    "# This function takes the text file and converts it into a DataFrame (a table) called 'pkmndata'\n",
    "pkmndata = pd.read_csv('pokemonData.csv')\n",
    "\n",
    "# .head() shows us the first 5 rows\n",
    "# Always run this immediately after loading to ensure the data looks the way you expect\n",
    "pkmndata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the dataset, as available on Kaggle, is as follows.\n",
    "Learn more : https://en.wikipedia.org/wiki/List_of_Pok%C3%A9mon\n",
    "\n",
    "> **\\#** : ID for each Pokemon (runs from 1 to 721)  \n",
    "> **Name** : Name of each Pokemon  \n",
    "> **Type 1** : Each Pokemon has a basic Type, this determines weakness/resistance to attacks  \n",
    "> **Type 2** : Some Pokemons are dual type and have a Type 2 value (set to nan otherwise)  \n",
    "> **Total** : Sum of all stats of a Pokemon, a general guide to how strong a Pokemon is  \n",
    "> **HP** : Hit Points, defines how much damage a Pokemon can withstand before fainting  \n",
    "> **Attack** : The base modifier for normal attacks by the Pokemon (e.g., scratch, punch etc.)  \n",
    "> **Defense** : The base damage resistance of the Pokemon against normal attacks  \n",
    "> **SP Atk** : Special Attack, the base modifier for special attacks (e.g. fire blast, bubble beam)  \n",
    "> **SP Def** : Special Defense, the base damage resistance against special attacks  \n",
    "> **Speed** : Determines which Pokemon attacks first each round  \n",
    "> **Generation** : Each Pokemon belongs to a certain Generation  \n",
    "> **Legendary** : Legendary Pokemons are powerful, rare, and hard to catch\n",
    "\n",
    "---\n",
    "\n",
    "Check the vital statistics of the dataset using the `type` and `shape` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data type : \", type(pkmndata))   # Ensure that it is a DF\n",
    "print(\"Data dims : \", pkmndata.shape)   # .shape returns a tuple: (Number of Rows, Number of Columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the variables (and their types) in the dataset using the `dtypes` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types of all the columns\n",
    "print(pkmndata.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Explore the Dataset\n",
    "\n",
    "Exploring any dataset requires a solid understanding of the domain -- it is Pokemon, in our case.    \n",
    "We understand the following basics regarding Pokemon, primarily from [Wikipedia](https://en.wikipedia.org/wiki/List_of_Pok%C3%A9mon) and [Bulbapedia](https://bulbapedia.bulbagarden.net/wiki/Generation).    \n",
    "\n",
    "> **Generation** : There are seven generations of Pokemon as of 2018, with 721 till Generation VI (this dataset).   \n",
    "> **Type** : Every Pokemon has a *primary* type, and some of them also have a *secondary* type -- dual-type ones.    \n",
    "> **Legendary** : These Pokemons are rare, powerful, and really hard to catch -- there are 38 upto Generation VI.    \n",
    "\n",
    "Way more trivia about Pokemon is available online -- but let's come back and retrieve more information from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ".info() is the single most useful command for a first look.\n",
    "It tells us:\n",
    "  - The name of every column\n",
    "  - The data type (int64 = whole numbers, object = text/string, float = decimals)\n",
    "  - The \"Non-Null Count\" (How many rows actually have data vs. being empty)\n",
    "\"\"\"\n",
    "pkmndata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generations of Pokemon in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .unique() gives us the list of distinct categories (e.g., [1, 2, 3...])\n",
    "print(\"Number of Generations :\", len(pkmndata[\"Generation\"].unique()))\n",
    "\n",
    "# .value_counts() counts how many rows exist for each category\n",
    "# Automatically sorts them from Most Common -> Least Common\n",
    "print(pkmndata[\"Generation\"].value_counts())\n",
    "\n",
    "# sb.catplot (Categorical Plot) draws a bar for each category.\n",
    "# kind=\"count\" tells Seaborn to calculate the frequency for us\n",
    "sb.catplot(y = \"Generation\", data = pkmndata, kind = \"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of Pokemon in the Dataset\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary Types in the Dataset\n",
    "print(\"Number of Primary Types :\", len(pkmndata[\"Type 1\"].unique()))\n",
    "\n",
    "# Pokemons of each Primary Type\n",
    "print(pkmndata[\"Type 1\"].value_counts())\n",
    "sb.catplot(y = \"Type 1\", data = pkmndata, kind = \"count\", height = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "note the dropna() function, that we use to drop NA values\n",
    "    In this case, some pkmn may be monotype (Type 2 = NA)\n",
    "\"\"\"\n",
    "# Secondary Types in the Dataset\n",
    "print(\"Number of Secondary Types :\", len(pkmndata[\"Type 2\"].dropna().unique()))\n",
    "\n",
    "# Pokemons of each Secondary Type\n",
    "print(pkmndata[\"Type 2\"].dropna().value_counts())\n",
    "sb.catplot(y = \"Type 2\", data = pkmndata, kind = \"count\", height = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pokemons with a Single Type -- I\n",
    "singletype_data = pkmndata[pkmndata[\"Type 2\"].isnull()] # If no \"Type 2\" --> Monotype (Single Type)\n",
    "print(\"Pokemons with just Type 1 :\", len(singletype_data))\n",
    "singletype_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pokemons with Dual Types -- I and II\n",
    "dualtype_data = pkmndata[pkmndata[\"Type 2\"].isnull() == False]  # If not null-Type 2, means have Type 2 --> Dual Type\n",
    "print(\"Pokemons with Types 1 and 2 :\", len(dualtype_data))\n",
    "dualtype_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of Pokemon over Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary Type over Generations\n",
    "sb.catplot(y = 'Type 1', data = pkmndata, col = 'Generation', kind = 'count', col_wrap = 2, height = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondary Type over Generations\n",
    "sb.catplot(y = 'Type 2', data = pkmndata, col = 'Generation', kind = 'count', col_wrap = 2, height = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type distribution of Dual-Type Pokemons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pokemons with Dual Types -- I and II\n",
    "dualtype_data = pkmndata[pkmndata[\"Type 2\"].isnull() == False]\n",
    "print(\"Pokemons with Types 1 and 2 :\", len(dualtype_data))\n",
    "\n",
    "\"\"\"\n",
    ".groupby(['Type 1', 'Type 2']): Group the data by every unique pair (e.g., Fire-Water)\n",
    "\n",
    ".size(): Count how many Pokemon are in each group\n",
    "\n",
    ".unstack(): Pivot the data. Turn the list of groups into a Matrix (Grid)\n",
    "    (Rows = Type 1, Columns = Type 2)\n",
    "\n",
    ".heatmap()\n",
    "    uses color intensity to show density\n",
    "    Darker squares = common combinations\n",
    "    Empty squares = combination doesn't exist in pkmn yet\n",
    "\n",
    "We have 18 Type 1s and 18 Type 2s --> 18 x 18 = 324 combinations\n",
    "Bar chart with 300+ bars would be unreadable\n",
    "Heatmap (grid) here would be easier to scan for patterns \n",
    "\"\"\"\n",
    "\n",
    "# Distribution of the Two Types\n",
    "f = plt.figure(figsize=(6, 6))\n",
    "sb.heatmap(dualtype_data.groupby(['Type 1', 'Type 2']).size().unstack(), \n",
    "           linewidths = 1, \n",
    "           annot = True,            # annot=True writes the actual number in the box\n",
    "           annot_kws = {\"size\": 8}, # Font size of the numbers\n",
    "           cmap = \"BuGn\")           # Color map: Blue to Green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the Two Types over Generations\n",
    "f, axes = plt.subplots(3, 2, figsize=(12, 18))\n",
    "\n",
    "dualtype_gen1 = dualtype_data[dualtype_data[\"Generation\"] == 1]\n",
    "dualtype_gen2 = dualtype_data[dualtype_data[\"Generation\"] == 2]\n",
    "dualtype_gen3 = dualtype_data[dualtype_data[\"Generation\"] == 3]\n",
    "dualtype_gen4 = dualtype_data[dualtype_data[\"Generation\"] == 4]\n",
    "dualtype_gen5 = dualtype_data[dualtype_data[\"Generation\"] == 5]\n",
    "dualtype_gen6 = dualtype_data[dualtype_data[\"Generation\"] == 6]\n",
    "\n",
    "sb.heatmap(dualtype_gen1.groupby(['Type 1', 'Type 2']).size().unstack(),\n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 6}, cmap = \"BuGn\", ax = axes[0,0])\n",
    "sb.heatmap(dualtype_gen2.groupby(['Type 1', 'Type 2']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 6}, cmap = \"BuGn\", ax = axes[0,1])\n",
    "sb.heatmap(dualtype_gen3.groupby(['Type 1', 'Type 2']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 6}, cmap = \"BuGn\", ax = axes[1,0])\n",
    "sb.heatmap(dualtype_gen4.groupby(['Type 1', 'Type 2']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 6}, cmap = \"BuGn\", ax = axes[1,1])\n",
    "sb.heatmap(dualtype_gen5.groupby(['Type 1', 'Type 2']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 6}, cmap = \"BuGn\", ax = axes[2,0])\n",
    "sb.heatmap(dualtype_gen6.groupby(['Type 1', 'Type 2']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 6}, cmap = \"BuGn\", ax = axes[2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Legendary Pokemons\n",
    "\n",
    "![Legendary Pokemons](images/PokemonLegendary.png)\n",
    "\n",
    "We understand that there are 65 Legendary Pokemons till Generation 6. Rare, powerful, interesting, and hard to catch. Let's explore them in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legendary Pokemons in the Dataset\n",
    "legnd_data = pkmndata[pkmndata[\"Legendary\"] == True]\n",
    "print(\"Number of Legendary Pokemons :\", len(legnd_data))\n",
    "\n",
    "# Legendary Pokemons in each Generation\n",
    "print(legnd_data[\"Generation\"].value_counts())\n",
    "sb.catplot(y = \"Generation\", data = legnd_data, kind = \"count\", height = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legendary Pokemons in the Dataset\n",
    "legnd_data = pkmndata[pkmndata[\"Legendary\"] == True]\n",
    "print(\"Number of Legendary Pokemons :\", len(legnd_data))\n",
    "\n",
    "# Legendary Pokemons in each Primary Type\n",
    "print(legnd_data[\"Type 1\"].value_counts())\n",
    "sb.catplot(y = \"Type 1\", data = legnd_data, kind = \"count\", \n",
    "           order = legnd_data[\"Type 1\"].value_counts().index, height = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legendary Pokemons with two Types -- I and II\n",
    "dualtype_legnd_data = legnd_data[legnd_data[\"Type 2\"].isnull() == False]\n",
    "print(\"Legendary Pokemons with Types 1 and 2 :\", len(dualtype_legnd_data))\n",
    "\n",
    "\n",
    "# Distribution over the Two Types\n",
    "f = plt.figure(figsize=(8, 8))\n",
    "sb.heatmap(dualtype_legnd_data.groupby(['Type 1', 'Type 2']).size().unstack(), \n",
    "           linewidths = 1, annot = True, annot_kws = {\"size\": 9}, cmap = \"BuGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Summary of Pokemon Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical Data\n",
    "\n",
    "To understand the distribution of stats (HP, Attk, Spd, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the numeric data variables\n",
    "numeric_data = pd.DataFrame(pkmndata[[\"HP\", \"Attack\", \"Defense\", \"Sp. Atk\", \"Sp. Def\", \"Speed\"]])\n",
    "\n",
    "# Summary Statistics for all Variables\n",
    "numeric_data.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the \"Big Three\" plots\n",
    "    When looking at numbers (e.g. HP, Attack, Speed), we care about the Distribution.\n",
    "    E.g., is the data clustered in the middle, are there extreme values (outliers)?\n",
    "\n",
    "Boxplot\n",
    "    Best for spotting outliers (the dots outside the whiskers) and\n",
    "    checking where the middle 50% of the data sits.\n",
    "    \n",
    "Histogram\n",
    "    Best for seeing the shape (is it a bell curve? is it skewed to the left?)\n",
    "    \n",
    "Violin Plot\n",
    "    Combination of the two. Shows the boxplot's range, but also the\n",
    "    Histogram's \"fatness\" density\n",
    "\"\"\"\n",
    "\n",
    "# Draw the distributions of all variables\n",
    "f, axes = plt.subplots(6, 3, figsize=(18, 24))\n",
    "\n",
    "count = 0\n",
    "for var in numeric_data:\n",
    "    sb.boxplot(data = numeric_data[var], orient = \"h\", ax = axes[count,0])\n",
    "    sb.histplot(data = numeric_data[var], ax = axes[count,1])\n",
    "    sb.violinplot(data = numeric_data[var], orient = \"h\", ax = axes[count,2])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ".corr() measures linear relationships between -1 and 1\n",
    "\n",
    "Remember: Heatmap is a clearer visualization of the correlation matrix (Useful figure)\n",
    "\"\"\"\n",
    "# Correlation Matrix\n",
    "print(numeric_data.corr())\n",
    "\n",
    "# Heatmap of the Correlation Matrix\n",
    "f = plt.figure(figsize=(6, 6))\n",
    "sb.heatmap(numeric_data.corr(), vmin = -1, vmax = 1, linewidths = 1,\n",
    "           annot = True, fmt = \".2f\", annot_kws = {\"size\": 8}, cmap = \"RdBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw pairs of variables against one another\n",
    "sb.pairplot(data = numeric_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Dataset (Pre-processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique Names and IDs of Pokemons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Unique Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .unique() returns an array of every distinct name found in the column.\n",
    "# len() counts the length of that array.\n",
    "# If this number matches the total row count (800), every name is unique.\n",
    "print(\"Unique Names of Pokemon :\", len(pkmndata[\"Name\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Unique IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do the same check for the ID column (\"#\").\n",
    "# If this number is LOWER than the total rows, it means some IDs are repeated\n",
    "print(\"Unique IDs of Pokemon :\", len(pkmndata[\"#\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know duplicates exist (from the previous step). Now we want to see them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .duplicated(\"#\", keep=False):\n",
    "#   - Scans the \"#\" column.\n",
    "#   - keep=False is CRITICAL here. Normally, Python keeps the first copy and marks the rest as duplicates.\n",
    "#     By saying keep=False, we tell it: \"Mark ALL instances as True.\"\n",
    "#     We want to see the original AND the copy side-by-side to compare them.\n",
    "dupid_data = pkmndata[pkmndata.duplicated(\"#\", keep = False)]\n",
    "\n",
    "# .sort_values(by=\"Name\"):\n",
    "#   - We sort alphabetically so the duplicate pairs sit next to each other (e.g., Venusaur and VenusaurMega).\n",
    "# .head(10):\n",
    "#   - We only look at the first 10 rows to verify our code worked.\n",
    "dupid_data.sort_values(by = \"Name\").head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a duplicate report. This block prints a clean list of which Pokemon share the same ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many rows are involved in the duplication\n",
    "print(\"Pokemons with Duplicate IDs :\", len(dupid_data))\n",
    "\n",
    "# Get a list of the specific ID numbers that are repeated\n",
    "dupids = dupid_data[\"#\"].unique()\n",
    "print(\"Unique Pokemons with DupIDs :\", len(dupids))\n",
    "print()\n",
    "\n",
    "print(\"# \\t Count \\t List of Pokemons with Duplicate IDs\")\n",
    "print()\n",
    "\n",
    "# This runs once for every problem ID found.\n",
    "for dupid in dupids:\n",
    "\n",
    "    # Filter: Get only the rows matching the current Duplicate ID\n",
    "    # Select: Get only the \"Name\" column\n",
    "    # List: Convert the result into a standard Python list for printing\n",
    "    dupid_list = list(dupid_data[dupid_data[\"#\"] == dupid][\"Name\"])\n",
    "\n",
    "    print(dupid, \"\\t\", len(dupid_list), \"\\t\", dupid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Clean the Dataset\n",
    "\n",
    "Once we are done with the basic exploration of variables, it's time to *clean* and *tidy-up* the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Standardizing Column Names.\n",
    "\n",
    "Objective: Remove spaces, punctuation, and capitalization differences.\n",
    "\n",
    "Why? In Python, `df.Attack` works, but `df.Sp. Atk` crashes because of the space and dot.\n",
    "\"\"\"\n",
    "\n",
    "# In Python, variables are often \"pointers.\" If we just said df_clean = df, \n",
    "# changing df_clean would ALSO destroy our original raw data.\n",
    "# .copy() forces Python to create a physically separate backup.\n",
    "pkmndata_clean = pkmndata.copy()    # .copy() is crucial! \n",
    "\n",
    "# Rename \"#\" to \"ID\" of Pokemon\n",
    "# inplace=True means \"save this change directly into pkmndata_clean\", \n",
    "# rather than creating a new table.\n",
    "pkmndata_clean.rename(columns = {'#': 'ID'}, inplace = True)\n",
    "\n",
    "# Convert all Variable Names to UPPERCASE\n",
    "# .str is an accessor that lets us treat the column names like text strings.\n",
    "pkmndata_clean.columns = pkmndata_clean.columns.str.upper()\n",
    "\n",
    "# Remove all spaces and dots from Variable Names\n",
    "# We replace dots \".\" with nothing \"\" (deleting them).\n",
    "# We replace spaces \" \" with underscores \"_\" (snake_case).\n",
    "# Result: \"Sp. Atk\" becomes \"SP_ATK\". Much easier to code with!\n",
    "pkmndata_clean.columns = pkmndata_clean.columns.str.replace(\".\",\"\")\n",
    "pkmndata_clean.columns = pkmndata_clean.columns.str.replace(\" \",\"_\")\n",
    "\n",
    "# Print the Variable Information to check\n",
    "pkmndata_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix Pokemon Names\n",
    "\n",
    "We take cue from the Pokedex dataset (https://pokemondb.net/pokedex/all), and perform the following (not in order).   \n",
    "\n",
    "> Convert `[Name]Mega [Name]` to `[Name]Mega`    \n",
    "> Convert `[Name]Mega [Name] X` to `[Name]MegaX`    \n",
    "> Convert `[Name]Mega [Name] Y` to `[Name]MegaY`    \n",
    "> Convert `[Name][Form] Forme` to `[Name][Form]`    \n",
    "> Convert `[Name][Cloak] Cloak` to `[Name][Cloak]`    \n",
    "> Convert `[Name][Rotom] Rotom` to `[Name][Rotom]`    \n",
    "> Convert `[Name][Size] Size` to `[Name][Size]`    \n",
    "> Convert `HoopaHoopa [Form]` to `Hoopa[Form]`     \n",
    "\n",
    "Regular Expression (RegEx) search-and-replace is a lovely tool to accomplish such tasks. We use `re` library in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is like \"Find and Replace\" on steroids. \n",
    "Concept: re.sub(pattern, replacement, text) looks for a pattern and swaps it out.\n",
    "\n",
    "This block is complex. You don't need to memorize the Regex syntax per se.\n",
    "Focus on our goal:\n",
    "    Telling the script to spot patterns (e.g., words ending in `Forme`) \n",
    "    and chop them off\n",
    "\"\"\"\n",
    "# Fix the weird Names of Pokemons\n",
    "import re # \"re\" is the library for Regular Expressions\n",
    "\n",
    "# LAMBDA EXPLANATION:\n",
    "# .apply(lambda x: ...): \n",
    "# Think of this as a mini-loop. \"For every single name 'x' in this column, apply this rule...\"\n",
    "\n",
    "# REGEX EXPLANATION: r'(.+)(Forme)'\n",
    "# (.+) means \"Group 1: Any text\" (e.g., \"Venusaur\")\n",
    "# (Forme) means \"Group 2: The word Forme\"\n",
    "# r'\\1' means \"Replace the whole thing with just Group 1\".\n",
    "# Result: \"VenusaurForme\" becomes \"Venusaur\".\n",
    "\n",
    "# Fix names with extra Extensions (removing \"Forme\", \"Cloak\", \"Rotom\", \"Size\")\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'(.+)(Forme)',r'\\1', x))\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'(.+)(Cloak)',r'\\1', x))\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'(.+)(Rotom)',r'\\1', x))\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'(.+)(Size)',r'\\1', x))\n",
    "\n",
    "# Special case for Hoopa: Keep the SECOND part (Group 2)\n",
    "# r'(Hoopa)(.+)' -> Keep Group 2 (\\2).\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'(Hoopa)(.+)',r'\\2', x))\n",
    "\n",
    "# Fix names with Mega in between\n",
    "# Example: \"VenusaurMega Venusaur\" -> Keep \"VenusaurMega\"\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'(.+Mega)(.+)',r'\\1', x))\n",
    "\n",
    "# Remove Blanks from all the Names\n",
    "# \\s+ matches one or more empty spaces. We replace them with '' (nothing).\n",
    "pkmndata_clean[\"NAME\"] = pkmndata_clean[\"NAME\"].apply(lambda x: re.sub(r'\\s+','', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check the duplicates again to see if our name cleaning worked.\n",
    "dupid_data_clean = pkmndata_clean[pkmndata_clean.duplicated(\"ID\", keep = False)]\n",
    "print(\"Pokemons with Duplicate IDs :\", len(dupid_data_clean))\n",
    "\n",
    "dupids_clean = dupid_data_clean[\"ID\"].unique()\n",
    "print(\"Unique Pokemons with DupIDs :\", len(dupids_clean))\n",
    "print()\n",
    "\n",
    "# Print the list to scan for remaining errors\n",
    "# We expect to see nice clean names now (e.g., \"Venusaur\" and \"VenusaurMega\").\n",
    "print(\"# \\t Count \\t List of Pokemons with Duplicate IDs\")\n",
    "print()\n",
    "for dupid_clean in dupids_clean:\n",
    "    dupid_list_clean = list(dupid_data_clean[dupid_data_clean[\"ID\"] == dupid_clean][\"NAME\"])\n",
    "    print(dupid_clean, \"\\t\", len(dupid_list_clean), \"\\t\", dupid_list_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual Edge-Case Fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: Some errors are too specific for a pattern (RegEx). \n",
    "We must fix them manually. \n",
    "\n",
    "Problem: Charizard Mega X and Mega Y might have been named identically \n",
    "in the raw data, or stripped too aggressively.\n",
    "\"\"\"\n",
    "\n",
    "# Check the current state of Charizard (ID 6) and Mewtwo (ID 150)\n",
    "print(pkmndata_clean[pkmndata_clean[\"ID\"] == 6][\"NAME\"])\n",
    "print(pkmndata_clean[pkmndata_clean[\"ID\"] == 150][\"NAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .loc[row_index, column] = value\n",
    "# NOTE: The numbers 7, 8, 163, 164 are the DataFrame INDICES (Row Numbers), not the Pokemon IDs.\n",
    "# We are hard-coding these specific rows to have the correct names.\n",
    "\n",
    "# Fix the X,Y labels for Charizard and Mewtwo\n",
    "pkmndata_clean.loc[7,\"NAME\"] = \"CharizardMegaX\"\n",
    "pkmndata_clean.loc[8,\"NAME\"] = \"CharizardMegaY\"\n",
    "pkmndata_clean.loc[163,\"NAME\"] = \"MewtwoMegaX\"\n",
    "pkmndata_clean.loc[164,\"NAME\"] = \"MewtwoMegaY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set NAME as the Index of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before: Rows were labeled 0, 1, 2, 3...\n",
    "# After: Rows are labeled \"Bulbasaur\", \"Ivysaur\", \"Venusaur\"...\n",
    "# This makes searching intuitive: df.loc['Pikachu'] is easier than df.loc[25]\n",
    "pkmndata_clean = pkmndata_clean.set_index('NAME')\n",
    "\n",
    "# Print the DataFrame to check\n",
    "# .sample(n=10) grabs 10 random rows. \n",
    "# It's sometimes better than .head() because it shows you data from the middle/end too.\n",
    "pkmndata_clean.sample(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Variable Information\n",
    "# Confirming everything is the right data type and shape.\n",
    "pkmndata_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tackle the Missing Values\n",
    "\n",
    "Note that `TYPE_2` has only 414 values, instead of the overall 800. Let's fill-in the missing values with the string `NoType` for clarity about single/dual types.     \n",
    "\n",
    "\n",
    "Missing values are generally represented as `NaN` in numeric arrays, `None` or `NaN` in object arrays, `NaT` in datetime. In certain cases, the missing values may mean the data is not available or not required (as in here). But it may also be errors from data acquisition or data processing. We should check for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .isnull() returns a True/False table (True = Missing).\n",
    "# .sum() counts the Trues. \n",
    "# We expect TYPE_2 to have many missing values (monotype Pokemon).\n",
    "pkmndata_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Handling Missing Data\n",
    "\n",
    "We have two choices:\n",
    "    1. Drop the rows (Bad! We lose half our Pokemon).\n",
    "    2. Fill the empty space with a label.\n",
    "\n",
    "We choose option 2. We fill NaNs with the string \"NoType\".\n",
    "\"\"\"\n",
    "\n",
    "# .fillna(value=...): The function to fill N/A (Not Available) values.\n",
    "# inplace=True: Update the dataframe directly without creating a new variable.\n",
    "pkmndata_clean[\"TYPE_2\"].fillna(value = \"NoType\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Clean Dataset\n",
    "# We run .info() again to see the \"Non-Null Count\".\n",
    "# Before: TYPE_2 might have said \"414 non-null\".\n",
    "# After: It should say \"800 non-null\" (matching the Total entries).\n",
    "pkmndata_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Variable Information\n",
    "# .value_counts() counts how many Pokemon belong to each Type 2 category.\n",
    "# Note: The .dropna() here is actually redundant because we just filled all the N/As! \n",
    "# It's likely left over from code before we fixed the data, acting as a safety net.\n",
    "print(pkmndata_clean[\"TYPE_2\"].dropna().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pokemons worth Exploring\n",
    "\n",
    "![My Favorites](images/PokemonMyFabs.png)\n",
    "\n",
    "Of course, we all have our favourite Pokemons -- mine are Pikachu, Jigglypuff, Togepi, Bulbasaur and Snorlax -- as you can tell from the image above.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My Favorites (entirely based on cuteness index, and not on their power)\n",
    "pkmndata_clean.loc[[\"Pikachu\", \"Jigglypuff\", \"Togepi\", \"Bulbasaur\", \"Snorlax\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there are some other Pokemons worth exploring -- especially the strongest and the weakest Pokemons, may be for each type and generation.\n",
    "\n",
    "#### Strongest and Weakest Pokemons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strongest Pokemons -- the Top 10\n",
    "# Ascending = False --> Descending\n",
    "pkmndata_clean.sort_values('TOTAL', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weakest Pokemons -- the Bottom 10\n",
    "# Ascending = True --> Low to High\n",
    "pkmndata_clean.sort_values('TOTAL', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strongest and Weakest Pokemons -- Legendary and Non-Legendary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strongest Legendary Pokemons -- the Top 10\n",
    "pkmndata_clean[pkmndata_clean[\"LEGENDARY\"] == True].sort_values('TOTAL', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weakest Legendary Pokemons -- the Bottom 10\n",
    "pkmndata_clean[pkmndata_clean[\"LEGENDARY\"] == True].sort_values('TOTAL', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strongest Non-Legendary Pokemons -- the Top 10\n",
    "pkmndata_clean[pkmndata_clean[\"LEGENDARY\"] == False].sort_values('TOTAL', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weakest Non-Legendary Pokemons -- the Bottom 10\n",
    "pkmndata_clean[pkmndata_clean[\"LEGENDARY\"] == False].sort_values('TOTAL', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strongest and Weakest Pokemons -- Across Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strongest Pokemons in each Generation -- the Top 10\n",
    "generation = 1\n",
    "pkmndata_clean[pkmndata_clean[\"GENERATION\"] == generation].sort_values('TOTAL', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weakest Pokemons in each Generation -- the Bottom 10\n",
    "generation = 1\n",
    "pkmndata_clean[pkmndata_clean[\"GENERATION\"] == generation].sort_values('TOTAL', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strength of Pokemons over various Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which combination of types is the strongest? To answer this, we need to aggregate the data.\n",
    "\n",
    "We will calculate the **Average Total Stats** for every pair of `TYPE_1` and `TYPE_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ".groupby(['TYPE_1', 'TYPE_2']):\n",
    "   Imagine sorting the Pokemon into physical buckets based on their pair of types\n",
    "   Bucket 1: \"Fire + Flying\" (Charizard, Moltres...)\n",
    "   Bucket 2: \"Grass + Poison\" (Bulbasaur, Vileplume...)\n",
    "   \n",
    ".mean():\n",
    "   Inside each bucket, calculate the average of ALL numerical columns\n",
    "   (e.g., The average Attack of all Fire/Flying Pokemon)\n",
    "\n",
    ".loc[:, 'TOTAL']:\n",
    "   We only care about the 'TOTAL' strength for this specific analysis\n",
    "   .loc[ : , 'TOTAL' ] means: \"Keep all the Groups (rows), but give me only the 'TOTAL' column\n",
    "   \"\n",
    "\"\"\"\n",
    "# Calculate the Mean Total for every Type Pair\n",
    "total_means = pkmndata_clean.groupby(['TYPE_1', 'TYPE_2']).mean().loc[:, 'TOTAL']\n",
    "\n",
    "\"\"\"\n",
    "The `total_means` variable is currently a \"Series\" with a Multi-Index (Type 1 and Type 2 are the labels).\n",
    "To read it like a normal table, we need to massage the data.\n",
    "\n",
    ".reset_index():\n",
    "   Converts the labels (Type 1, Type 2) back into regular columns. \n",
    "   Now it looks like a standard DataFrame (Table) again.\n",
    "\n",
    ".sort_values('TOTAL', ascending=False):\n",
    "   Sort by the Total Strength. \n",
    "   ascending=False means \"High to Low\" (Descending).\n",
    "\n",
    ".head(10):\n",
    "   Show only the first 10 rows.\n",
    "\"\"\"\n",
    "print(\"Top 10 Strongest Type Combinations:\")\n",
    "print(total_means.reset_index().sort_values('TOTAL', ascending=False).head(10).round(2))\n",
    "\n",
    "# Initialize the figure size\n",
    "f = plt.figure(figsize=(10, 10))\n",
    "\"\"\"\n",
    "Currently, `total_means` is a \"Long List\":\n",
    "  Fire-Water: 500\n",
    "  Fire-Grass: 450\n",
    "  ...\n",
    "\n",
    "We need a \"Wide Matrix\" where:\n",
    "  - Rows    = TYPE_1\n",
    "  - Columns = TYPE_2\n",
    "  - Values  = Average TOTAL\n",
    "\n",
    ".unstack() performs this pivot. It takes the inner index (TYPE_2) and rotates it to become the columns.\n",
    "\"\"\"\n",
    "# Draw the Heatmap\n",
    "sb.heatmap(\n",
    "    total_means.unstack(),     # The Data (Converted to a Matrix)\n",
    "    linewidths = 1,            # Gap between squares\n",
    "    annot = True,              # Show the actual numbers inside the squares\n",
    "    fmt = \".0f\",               # Format the numbers: \".0f\" means 0 decimal places (Whole numbers)\n",
    "    annot_kws = {\"size\": 8},   # Size of the text inside the squares\n",
    "    cmap = \"BuGn\"              # Color Map: Blue to Green (Darker = Stronger)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strength of Legendary Pokemons over various Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Average TOTAL across every pair of TYPEs\n",
    "total_means = pkmndata_clean[pkmndata_clean[\"LEGENDARY\"] == True].groupby(['TYPE_1', 'TYPE_2']).mean().loc[:, 'TOTAL']\n",
    "\n",
    "# Strongest Pokemons in each Pair of Types -- the Top 10\n",
    "print(total_means.reset_index().sort_values('TOTAL', ascending=False).head(10).round(2))\n",
    "\n",
    "# Heatmap of Average TOTAL across every pair of TYPEs\n",
    "f = plt.figure(figsize=(10, 10))\n",
    "sb.heatmap(total_means.unstack(), linewidths = 1,\n",
    "           annot = True, fmt = \".0f\", annot_kws = {\"size\": 8}, cmap = \"BuGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential Steps in Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 1. **Setup & Initial Inspection**\n",
    "\n",
    "- **Loading Data**: Using `pandas.read_csv()` to convert raw files into a structured DataFrame.\n",
    "\n",
    "- **Structure Analysis**: Using `.shape` to check dimensions (rows/columns) and `.info()` to inspect column names, data types (int vs object), and non-null counts.\n",
    "\n",
    "- **Categorial Overview**: Using `.unique()` to count distinct values and `.value_counts()` to identify frequency distributions (e.g., imbalance in Pokemon Generations).\n",
    "\n",
    "### 2. **Univariate Analysis (One Variable)**\n",
    "\n",
    "- **Categorical Visualization**: Using `sb.catplot(kind='count')` to plot frequency bars for categorical variables (e.g., 'Type1' or 'Generation').\n",
    "\n",
    "- **Numerical Distributions**: Using the 'Big Three' plots to understand stats:\n",
    "\n",
    "    - **Boxplot** (`sb.boxplot`): To identify quartiles and spot outliers.\n",
    "\n",
    "    - **Histogram** (`sb.histplot`): To see the frequency distribution shape (Normal vs. Skewed).\n",
    "\n",
    "    - **Violin Plot** (`sb.violinplot`): To combine boxplot range with density estimation.\n",
    "\n",
    "- **Statistical Summary**: Using `.describe()` to view key metrics (mean, std, min, max) for all numerical features.\n",
    "\n",
    "### 3. **Data Cleaning & Pre-processing**\n",
    "\n",
    "- **Duplicate Management**: Using `.duplicated(keep=False)` tto flag and inspect all instances of repeated IDs before deciding how to handle them.\n",
    "\n",
    "- **Column Standardization**: Using `.rename()`, `.str.upper()`, and `.str.replace()` to convert messy headers into clean, upper-case \"snake_case\" (e.g., changing `Sp. Atk' to 'SP_ATK').\n",
    "\n",
    "- **Pattern Matching (Regex)**: Using `re.sub()` inside a `.apply(lambda x: ...)` function to strip unwanted substrings (like \"Forme\" and \"Cloak\") from text data.\n",
    "\n",
    "- **Manual Correction** Using `.loc[row_index, col_name]` to manually fix specific edge cases that automated cleaning misses (e.g. 'Charizard MegaX' and 'Charizard MegaY')\n",
    "\n",
    "- **Handling Missing Values**: Using `.isnull().sum()` to detect gaps and `.fillna()` to fill missing data (e.g., filling missing 'Type2' with 'NoType' string) rather than deleting rows.\n",
    "\n",
    "### 4. Bivariate & Multi-Variate Analysis\n",
    "\n",
    "- **Correlation Analysis**: Using `.corr()` to calculate linear relationships and `sb.heatmap()` to visualize the correlation matrix (e.g., identifying if Defense relates to Speed).\n",
    "\n",
    "- **Filtering & Sorting**: Using Boolean indexing (e.g., `data['Legendary'] == True`) to isolate subsets and `.sort_values(ascending=False)` to rank data (e.g., finding the strongest Pokemon)\n",
    "\n",
    "- **Aggregation**: Using `.groupby(['Col1', 'Col2']).mean()` to calculate statistics for specific combinations (e.g., Average Stats for every Type pair). \n",
    "\n",
    "- **Data Pivoting**: Using `.unstack()` to transform a long list of grouped values into a matrix/grid format, enabling 2-D Heatmap Visualization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
